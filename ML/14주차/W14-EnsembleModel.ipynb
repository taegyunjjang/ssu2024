{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 머신러닝   \n",
    "       \n",
    "14주 1강: 앙상블 모델\n",
    "\n",
    "이번 시간에는 작은 모델들의 예측을 모아 성능을 높이는 앙상블 모델을 돌아보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 앙상블 모델\n",
    "**앙상블 모델(Ensemble Model)** 은  여러 개의 개별 모델을 조합하여 최적의 모델로 일반화하는 방법을 말합니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 투표 분류기\n",
    "### 가장 단순한 투표 분류기\n",
    "* 단순하게 여러 모델을 만들어 \"투표\"를 하게 하는 투표 분류기를 만들어 봅시다\n",
    "* `scikit-learn.ensemble.VotingClassifier`를 쓰시면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 먼저 데이터를 로드해 봅시다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(\"W14/titanic_X_train.npy\")\n",
    "y = np.load(\"W14/titanic_y_train.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.27345609, 0.01415106, 0.        , 1.        , 0.        ,\n",
       "       0.125     , 0.        , 0.        , 0.        , 1.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       1.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        ])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 1., 0., 0., 0., 0., 1., 1.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 모델을 생성하기 앞서 우리가 배운 가장 기본적인 모델 3가지(`LogisticRegression`, `DecisionTreeClassifier`, `GaussianNB`를 기본 모델로 삼습니다\n",
    "* scikit-learn에선 이런 것들을 예측기 (estimator)라고 부릅니다\n",
    "  * 리스트 형태로 `VotingClassifier` 의 인자로 넣을 수 있습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = DecisionTreeClassifier(random_state=1, max_depth=4)\n",
    "clf3 = GaussianNB()\n",
    "\n",
    "eclf = VotingClassifier(\n",
    "    estimators=[('lr', clf1), ('rf', clf2), ('gnb',clf3)], voting='hard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 앙상블 모델의 성능을 측정해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8222941661905668)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(eclf, X, y, cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 개별 모델들의 성능을 봅시다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8290420872214816)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "cross_val_score(clf1, X, y, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8223068621849807)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree\n",
    "cross_val_score(clf2, X, y, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.4600139655938551)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "cross_val_score(clf3, X, y, cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* GNB가 성능이 좋지 않은 것을 알 수 있습니다. \n",
    "  * GNB는 연속 데이터에 잘 맞는 모델로, 이러한 이산 데이터에 잘 맞지 않을 수 있습니다\n",
    "  * 이를 빼고 성능을 다시 측정해봅시다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8301783787215135)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eclf = VotingClassifier(\n",
    "    estimators=[('lr', clf1), ('rf', clf2)], voting='hard')\n",
    "cross_val_score(eclf, X, y, cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 성능이 올랐습니다!\n",
    "  * 투표 모델에서 꼭 많은 수의 모델을 쓴다고 더 좋은 성능을 내 주는 것은 아닙니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하이퍼 파라미터를 튜닝한 투표 분류기\n",
    "* 성능을 더 올리려면 하이퍼 매개변수를 튜닝해볼 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = DecisionTreeClassifier(random_state=1)\n",
    "eclf = VotingClassifier(estimators=[('lr', clf1), ('dt', clf2)], voting='hard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 파라미터를 지정하고, `GridSearchCV`를 생성해서 모델을 만듭시다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_params = [0.1, 5.0, 7.0, 10.0, 15.0, 20.0, 100.0]\n",
    "\n",
    "params ={\n",
    "    \"lr__solver\" :\n",
    "        ['liblinear'], \"lr__penalty\" : [\"l2\"], \"lr__C\" : c_params,\n",
    "    \"dt__criterion\" : [\"gini\", \"entropy\"],\n",
    "    \"dt__max_depth\" : [10,8,7,6,5,4,3,2],\n",
    "    \"dt__min_samples_leaf\": [1,2,3,4,5,6,7,8,9]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8425569732749316)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(estimator=eclf, param_grid=params, cv=5)\n",
    "grid = grid.fit(X, y)\n",
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 아래의 상태에서 가장 좋은 성능을 내 주는 것을 알 수가 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dt__criterion': 'gini',\n",
       " 'dt__max_depth': 10,\n",
       " 'dt__min_samples_leaf': 5,\n",
       " 'lr__C': 5.0,\n",
       " 'lr__penalty': 'l2',\n",
       " 'lr__solver': 'liblinear'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 배깅과 랜덤 포레스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 배깅\n",
    "* 배깅은 하나의 데이터셋에서 샘플링으로 여러 데이터를 만든 다음 데이터마다 모델을 만들어서 투표분류기를 만드는 기법입니다. \n",
    "* 부트스트래핑이라는 기법을 씁니다\n",
    "  * 모집단부터 학습 데이터를 추출할 때 복원추출을 반복합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 랜덤 포레스트\n",
    "* 배깅에서 가장 많이 쓰이고 유명한 모델은 랜덤 포레스트 입니다\n",
    "* 배깅을 의사결정트리에 적용한 모델입니다.\n",
    "\n",
    "* 배깅은 scikit-learn에는 `sklearn.ensemble.BaggingClassifier`를 쓰시면 됩니다\n",
    "\n",
    "* 주요 파라미터는 아래와 같습니다.\n",
    "  * `base_estimator` : 사용될 수 있는 모델(default=None)\n",
    "  * `n_estimators` : int, optional(default=10), subset으로 생성되는 모델의 개수\n",
    "  * `max_samples` : int or float, optional(default=1.0), 최대 데이터 개수 또는 비율\n",
    "  * `max_features` : int or float, optional(default=1.0), 최대 사용 피쳐 또는 비율\n",
    "  * `bootstrap` : boolean, optional(default=True), bootstrap 사용 여부\n",
    "  * `oob_score` : boolean, oob score 산출 여부\n",
    "  * `warm_start` : booeanl, optional(default=False), 이전에 학습된 모델을 사용할 것인가에 대한 정보"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 일단 모델을 생성해 봅시다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8267948962102458)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "X = np.load(\"W14/titanic_X_train.npy\")\n",
    "y = np.load(\"W14/titanic_y_train.npy\")\n",
    "clf1 = LogisticRegression(random_state=1)\n",
    "eclf = BaggingClassifier(clf1, oob_score=True, n_estimators=50) # Userwarning을 막기 위해 \n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(eclf, X, y, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8312892782327175)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params ={\n",
    "    #\"n_estimators\" : [10,20,30,40,50,55],\n",
    "    \"n_estimators\" : [40,50,55], # Userwarning을 막기 위해\n",
    "    \"max_samples\" : [0.5,0.6,0.7,0.8,0.9,1]\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(estimator=eclf, param_grid=params, cv=5)\n",
    "grid = grid.fit(X, y)\n",
    "\n",
    "grid.best_score_\n",
    "\n",
    "# Warning이많이 발생합니다. 파라미터 문제..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_samples': 0.9, 'n_estimators': 55}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8323959505061868"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `sklearn.ensemble.RandomForestClassifier` 로 직접 구현된 버전도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.7975750650669714)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X = np.load(\"W14/titanic_X_train.npy\")\n",
    "y = np.load(\"W14/titanic_y_train.npy\")\n",
    "\n",
    "eclf = RandomForestClassifier(n_estimators=100, max_features=2, n_jobs=7, oob_score=True)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(eclf, X, y, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jhyun/anaconda3/envs/ml2024/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:615: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.8234495016822192)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params ={\n",
    "    #\"n_estimators\" : [10, 20, 30, 50, 100],\n",
    "    \"n_estimators\" : [30, 50, 100],\n",
    "    \"max_features\" : [1,2,3,4,5,6,7, 10, 15, 20, 25, len(X[0])]\n",
    "    }\n",
    "\n",
    "grid = GridSearchCV(estimator=eclf, param_grid=params, cv=5)\n",
    "grid = grid.fit(X, y)\n",
    "\n",
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 15, 'n_estimators': 50}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8200224971878515"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 부스팅\n",
    "* 모델을 병렬로 만드는 배깅과 다르게, 부스팅은 틀렸던 답을 더 잘 맞추도록 다음 모델을 만들어 줍니다\n",
    "* 마치 오답노트를 만드는 것과 같습니다.\n",
    "* 병렬화가 어렵다는 단점이...\n",
    "* 일단 모델을 만들어 봅시다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.load(\"W14/titanic_X_train.npy\")\n",
    "y = np.load(\"W14/titanic_y_train.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 에이다부스트에 트리 모델을 결합할 것입니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#eclf = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=2), n_estimators=500) # 교과서의 잘못된 코드입니다.\n",
    "eclf = AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=2), n_estimators=500, algorithm=\"SAMME\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8279248397130706)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(eclf, X, y, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8020694470894434)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "eclf = RandomForestClassifier(n_estimators=500)\n",
    "cross_val_score(eclf, X, y, cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `GridSearchCV`로 최적 모델을 찾아봅시다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8222814701961532)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 아래에 해당하는 교과서 코드가 이상해서 수정을 좀 했습니다. \n",
    "\n",
    "eclf = AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=2), n_estimators=500, algorithm=\"SAMME\")\n",
    "\n",
    "params = {\"estimator__criterion\" : [\"gini\", \"entropy\"],\n",
    "          \"estimator__max_features\" : [7,8,],\n",
    "          \"estimator__max_depth\" : [1,2],\n",
    "          \"n_estimators\": [23,24, 25, 26, 27],\n",
    "          \"learning_rate\": [0.4, 0.45, 0.5, 0.55, 0.6]\n",
    "          }\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(estimator=eclf, param_grid=params, cv=5, n_jobs=7)\n",
    "grid = grid.fit(X, y)\n",
    "\n",
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimator__criterion': 'gini',\n",
       " 'estimator__max_depth': 2,\n",
       " 'estimator__max_features': 7,\n",
       " 'learning_rate': 0.6,\n",
       " 'n_estimators': 23}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.63652832e-02, 1.35372372e-01, 5.71357716e-02, 5.07146513e-02,\n",
       "       1.03749370e-01, 6.73581065e-02, 9.23193977e-02, 6.87948885e-03,\n",
       "       5.18089152e-16, 2.93754818e-02, 2.05661726e-03, 0.00000000e+00,\n",
       "       0.00000000e+00, 2.14127000e-02, 0.00000000e+00, 1.99362475e-01,\n",
       "       4.42392932e-05, 5.48274777e-02, 1.65561362e-02, 0.00000000e+00,\n",
       "       2.59273511e-02, 3.49727429e-03, 6.71287560e-03, 2.37344376e-02,\n",
       "       0.00000000e+00, 6.59849229e-03, 0.00000000e+00])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Today\n",
    "* 앙상블 모델\n",
    "  * 투표 모델\n",
    "  * 배깅 모델\n",
    "    * 부트스트래핑은 무엇인가\n",
    "  * 부스팅 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Next class\n",
    "- 시험... 시험을 봅시다.\n",
    "- 종강 축하드립니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml2024",
   "language": "python",
   "name": "ml2024"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
