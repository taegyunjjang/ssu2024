{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 단층 GRU 기반 생성 결과 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Vocabulary`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    \"\"\"매핑을 위해 텍스트를 처리하고 어휘 사전을 만드는 클래스 \"\"\"\n",
    "    \n",
    "    def __init__(self, token_to_idx=None):\n",
    "        \"\"\"\n",
    "        매개변수:\n",
    "            token_to_idx (dict): 기존 토큰-인덱스 매핑 딕셔너리\n",
    "        \"\"\"\n",
    "        \n",
    "        if token_to_idx is None:\n",
    "            token_to_idx = {}\n",
    "        self._token_to_idx = token_to_idx\n",
    "        self._idx_to_token = {idx: token \n",
    "                              for token, idx in self._token_to_idx.items()}\n",
    "\n",
    "    def to_serializable(self):\n",
    "        \"\"\" 직렬화할 수 있는 딕셔너리를 반환합니다 \"\"\"\n",
    "        return {'token_to_idx': self._token_to_idx}\n",
    "\n",
    "    @classmethod\n",
    "    def from_serializable(cls, contents):\n",
    "        \"\"\" 직렬화된 딕셔너리에서 Vocabulary 객체를 만듭니다 \"\"\"\n",
    "        return cls(**contents)\n",
    "\n",
    "    def add_token(self, token):\n",
    "        \"\"\" 토큰을 기반으로 매핑 딕셔너리를 업데이트합니다\n",
    "\n",
    "        매개변수:\n",
    "            token (str): Vocabulary에 추가할 토큰\n",
    "        반환값:\n",
    "            index (int): 토큰에 상응하는 정수\n",
    "        \"\"\"\n",
    "        if token in self._token_to_idx:\n",
    "            index = self._token_to_idx[token]\n",
    "        else:\n",
    "            index = len(self._token_to_idx)\n",
    "            self._token_to_idx[token] = index\n",
    "            self._idx_to_token[index] = token\n",
    "        return index\n",
    "            \n",
    "    def add_many(self, tokens):\n",
    "        \"\"\"토큰 리스트를 Vocabulary에 추가합니다.\n",
    "        \n",
    "        매개변수:\n",
    "            tokens (list): 문자열 토큰 리스트\n",
    "        반환값:\n",
    "            indices (list): 토큰 리스트에 상응되는 인덱스 리스트\n",
    "        \"\"\"\n",
    "        return [self.add_token(token) for token in tokens]\n",
    "\n",
    "    def lookup_token(self, token):\n",
    "        \"\"\"토큰에 대응하는 인덱스를 추출합니다.\n",
    "        \n",
    "        매개변수:\n",
    "            token (str): 찾을 토큰 \n",
    "        반환값:\n",
    "            index (int): 토큰에 해당하는 인덱스\n",
    "        \"\"\"\n",
    "        return self._token_to_idx[token]\n",
    "\n",
    "    def lookup_index(self, index):\n",
    "        \"\"\" 인덱스에 해당하는 토큰을 반환합니다.\n",
    "        \n",
    "        매개변수: \n",
    "            index (int): 찾을 인덱스\n",
    "        반환값:\n",
    "            token (str): 인텍스에 해당하는 토큰\n",
    "        에러:\n",
    "            KeyError: 인덱스가 Vocabulary에 없을 때 발생합니다.\n",
    "        \"\"\"\n",
    "        if index not in self._idx_to_token:\n",
    "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
    "        return self._idx_to_token[index]\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._token_to_idx)\n",
    "\n",
    "class SequenceVocabulary(Vocabulary):\n",
    "    def __init__(self, tokenizer, token_to_idx=None):\n",
    "\n",
    "        super(SequenceVocabulary, self).__init__(token_to_idx)\n",
    "\n",
    "        # KLUE RoBERTa 토크나이저에서 특수 토큰 설정\n",
    "        self._mask_token = tokenizer.mask_token\n",
    "        self._unk_token = tokenizer.unk_token\n",
    "        self._begin_seq_token = tokenizer.cls_token\n",
    "        self._end_seq_token = tokenizer.sep_token\n",
    "\n",
    "        self.mask_index = self.add_token(self._mask_token)\n",
    "        self.unk_index = self.add_token(self._unk_token)\n",
    "        self.begin_seq_index = self.add_token(self._begin_seq_token)\n",
    "        self.end_seq_index = self.add_token(self._end_seq_token)\n",
    "\n",
    "    def to_serializable(self):\n",
    "        contents = super(SequenceVocabulary, self).to_serializable()\n",
    "        contents.update({'unk_token': self._unk_token,\n",
    "                         'mask_token': self._mask_token,\n",
    "                         'begin_seq_token': self._begin_seq_token,\n",
    "                         'end_seq_token': self._end_seq_token})\n",
    "        return contents\n",
    "    \n",
    "    @classmethod\n",
    "    def from_serializable(cls, contents):\n",
    "        # KLUE RoBERTa 토크나이저 초기화\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"klue/roberta-base\")\n",
    "        \n",
    "        # token_to_idx만 추출하여 부모 클래스 초기화\n",
    "        token_to_idx = contents.get('token_to_idx', {})\n",
    "        return cls(tokenizer=tokenizer, token_to_idx=token_to_idx)\n",
    "\n",
    "    def lookup_token(self, token):\n",
    "        \"\"\" 토큰에 대응하는 인덱스를 추출합니다.\n",
    "        토큰이 없으면 UNK 인덱스를 반환합니다.\n",
    "        \n",
    "        매개변수:\n",
    "            token (str): 찾을 토큰 \n",
    "        반환값:\n",
    "            index (int): 토큰에 해당하는 인덱스\n",
    "        노트:\n",
    "            UNK 토큰을 사용하려면 (Vocabulary에 추가하기 위해)\n",
    "            `unk_index`가 0보다 커야 합니다.\n",
    "        \"\"\"\n",
    "        if self.unk_index >= 0:\n",
    "            return self._token_to_idx.get(token, self.unk_index)\n",
    "        else:\n",
    "            return self._token_to_idx[token]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Vectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommentVectorizer(object):\n",
    "    \"\"\"어휘 사전을 생성하고 관리합니다\"\"\"\n",
    "    \n",
    "    def __init__(self, text_vocab, tokenizer, target_vocab=None):\n",
    "        \"\"\"\n",
    "        매개변수:\n",
    "            text_vocab (SequenceVocabulary): 댓글 텍스트의 어휘 사전\n",
    "            target_vocab (Vocabulary, optional): 타겟 레이블의 어휘 사전\n",
    "            tokenizer (AutoTokenizer, optional): 토큰화를 위한 RoBERTa 토크나이저\n",
    "        \"\"\"\n",
    "        self.tokenizer = tokenizer\n",
    "        self.text_vocab = text_vocab\n",
    "        self.target_vocab = target_vocab\n",
    "\n",
    "    def vectorize(self, text, vector_length=-1):\n",
    "        \"\"\"댓글 텍스트를 입력 벡터와 출력 벡터로 변환\n",
    "        \n",
    "        매개변수:\n",
    "            text (str): 벡터로 변환할 댓글 텍스트\n",
    "            vector_length (int): 벡터의 고정 길이 (기본값: -1, 즉 가변 길이)\n",
    "        반환값:\n",
    "            tuple: (from_vector, to_vector)\n",
    "                from_vector (numpy.ndarray): 입력 텍스트의 벡터화 결과\n",
    "                to_vector (numpy.ndarray): 타겟 텍스트의 벡터화 결과\n",
    "        \"\"\"\n",
    "        # RoBERTa tokenizer로 토큰화\n",
    "        tokens = self.tokenizer.tokenize(text)\n",
    "        \n",
    "        # 1. 토큰을 인덱스로 변환\n",
    "        # COMPLETE YOUR CODE - START\n",
    "        token_indices = [self.text_vocab.lookup_token(token) for token in tokens]\n",
    "        \n",
    "        # COMPLETE YOUR CODE - END\n",
    "\n",
    "        # 2. from_vector 생성\n",
    "        # COMPLETE YOUR CODE - START\n",
    "        from_indices = [self.text_vocab.begin_seq_index] + token_indices\n",
    "        from_vector = np.zeros(vector_length + 1, dtype=np.int64)\n",
    "        from_vector[:len(from_indices)] = from_indices\n",
    "        \n",
    "        # COMPLETE YOUR CODE - END\n",
    "\n",
    "        # 3. to_vector 생성\n",
    "        # COMPLETE YOUR CODE - START\n",
    "        to_indices = token_indices + [self.text_vocab.end_seq_index]\n",
    "        to_vector = np.zeros(vector_length + 1, dtype=np.int64)\n",
    "        to_vector[:len(to_indices)] = to_indices\n",
    "        \n",
    "        # COMPLETE YOUR CODE - END\n",
    "\n",
    "        return from_vector, to_vector\n",
    "\n",
    "    @classmethod\n",
    "    def from_dataframe(cls, df):\n",
    "        \"\"\"데이터프레임을 이용해 CommentVectorizer 객체를 초기화\n",
    "        \n",
    "        매개변수:\n",
    "            df (pandas.DataFrame): 댓글 데이터프레임\n",
    "        반환값:\n",
    "            CommentVectorizer 객체\n",
    "        \"\"\"\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"klue/roberta-base\")\n",
    "        text_vocab = SequenceVocabulary(tokenizer=tokenizer)\n",
    "\n",
    "        # 텍스트 어휘 사전 구축\n",
    "        # COMPLETE YOUR CODE - START\n",
    "        for text in df.text:\n",
    "            tokens = tokenizer.tokenize(text)\n",
    "            text_vocab.add_many(tokens)\n",
    "        \n",
    "        # COMPLETE YOUR CODE - END\n",
    "\n",
    "        # 타겟 어휘 사전 구축\n",
    "        target_vocab = None\n",
    "        if 'target_label' in df.columns:\n",
    "            # COMPLETE YOUR CODE - START\n",
    "            target_vocab = Vocabulary()\n",
    "            for label in df['target_label']:\n",
    "                target_vocab.add_token(label)\n",
    "            \n",
    "            # COMPLETE YOUR CODE - END\n",
    "\n",
    "        return cls(text_vocab, tokenizer, target_vocab)\n",
    "\n",
    "    @classmethod\n",
    "    def from_serializable(cls, contents):\n",
    "        \"\"\"직렬화된 데이터를 사용해 CommentVectorizer 객체를 복원\n",
    "        \n",
    "        매개변수:\n",
    "            contents (dict): 직렬화된 데이터\n",
    "        반환값:\n",
    "            CommentVectorizer 객체\n",
    "        \"\"\"\n",
    "        # KLUE RoBERTa 토크나이저 초기화\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"klue/roberta-base\")\n",
    "\n",
    "        text_vocab = SequenceVocabulary.from_serializable(contents['text_vocab'])\n",
    "\n",
    "        # 타겟 어휘 사전 복원\n",
    "        target_vocab = None\n",
    "        if 'target_vocab' in contents:\n",
    "            target_vocab = Vocabulary.from_serializable(contents['target_vocab'])\n",
    "\n",
    "        return cls(text_vocab=text_vocab, target_vocab=target_vocab, tokenizer=tokenizer)\n",
    "\n",
    "    def to_serializable(self):\n",
    "        \"\"\"CommentVectorizer 객체를 직렬화 가능한 형태로 변환\n",
    "        \n",
    "        반환값:\n",
    "            dict: 직렬화된 데이터\n",
    "        \"\"\"\n",
    "        contents = {\n",
    "            'text_vocab': self.text_vocab.to_serializable()\n",
    "        }\n",
    "        if self.target_vocab:\n",
    "            contents['target_vocab'] = self.target_vocab.to_serializable()\n",
    "\n",
    "        return contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파이토치 데이터셋 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommentDataset(Dataset):\n",
    "    def __init__(self, comment_df, vectorizer):\n",
    "        \"\"\"\n",
    "        매개변수:\n",
    "            comment_df (pandas.DataFrame): 데이터셋\n",
    "            vectorizer (CommentVectorizer): 데이터셋에서 만든 Vectorizer 객체\n",
    "        \"\"\"\n",
    "        self.comment_df = comment_df\n",
    "        self._vectorizer = vectorizer\n",
    "\n",
    "        # 최대 시퀀스 길이 계산\n",
    "        self._max_seq_length = max(len(self._vectorizer.tokenizer.tokenize(text)) \n",
    "                                 for text in self.comment_df.text) + 2\n",
    "\n",
    "        # 데이터셋 분할\n",
    "        self.train_df = self.comment_df[self.comment_df.split == 'train']\n",
    "        self.train_size = len(self.train_df)\n",
    "\n",
    "        self.val_df = self.comment_df[self.comment_df.split == 'val']\n",
    "        self.validation_size = len(self.val_df)\n",
    "\n",
    "        self.test_df = self.comment_df[self.comment_df.split == 'test']\n",
    "        self.test_size = len(self.test_df)\n",
    "\n",
    "        self._lookup_dict = {\n",
    "            'train': (self.train_df, self.train_size),\n",
    "            'val': (self.val_df, self.validation_size),\n",
    "            'test': (self.test_df, self.test_size)\n",
    "        }\n",
    "\n",
    "        self.set_split('train')\n",
    "\n",
    "    @classmethod\n",
    "    def load_dataset_and_make_vectorizer(cls, dataset_csv):\n",
    "        \"\"\"데이터셋을 로드하고 새로운 Vectorizer를 만듭니다.\n",
    "        \n",
    "        매개변수:\n",
    "            dataset_csv (str): 데이터셋의 위치\n",
    "        반환값:\n",
    "            CommentDataset 객체\n",
    "        \"\"\"\n",
    "        comment_df = pd.read_csv(dataset_csv)\n",
    "        return cls(comment_df, CommentVectorizer.from_dataframe(comment_df))\n",
    "    \n",
    "    @classmethod\n",
    "    def load_dataset_and_load_vectorizer(cls, dataset_csv, vectorizer_filepath):\n",
    "        \"\"\"데이터셋과 캐싱된 Vectorizer 객체를 로드합니다.\n",
    "        \n",
    "        매개변수:\n",
    "            dataset_csv (str): 데이터셋의 위치\n",
    "            vectorizer_filepath (str): Vectorizer 객체의 저장 위치\n",
    "        반환값:\n",
    "            CommentDataset 객체\n",
    "        \"\"\"\n",
    "        comment_df = pd.read_csv(dataset_csv)\n",
    "        vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\n",
    "        return cls(comment_df, vectorizer)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_vectorizer_only(vectorizer_filepath):\n",
    "        \"\"\"파일에서 Vectorizer 객체를 로드하는 정적 메서드\n",
    "        \n",
    "        매개변수:\n",
    "            vectorizer_filepath (str): 직렬화된 Vectorizer 객체의 위치\n",
    "        반환값:\n",
    "            CommentVectorizer 객체\n",
    "        \"\"\"\n",
    "        with open(vectorizer_filepath) as fp:\n",
    "            return CommentVectorizer.from_serializable(json.load(fp))\n",
    "\n",
    "    def get_vectorizer(self):\n",
    "        \"\"\"벡터 변환 객체를 반환합니다\"\"\"\n",
    "        return self._vectorizer\n",
    "\n",
    "    def set_split(self, split=\"train\"):\n",
    "        \"\"\"데이터셋의 분할을 설정합니다.\"\"\"\n",
    "        self._target_split = split\n",
    "        self._target_df, self._target_size = self._lookup_dict[split]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._target_size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"파이토치 데이터셋의 주요 진입 메서드\"\"\"\n",
    "        # COMPLETE YOUR CODE - START\n",
    "        row = self._target_df.iloc[index]\n",
    "        from_vector, to_vector = self._vectorizer.vectorize(row.text, self._max_seq_length)\n",
    "\n",
    "        # COMPLETE YOUR CODE - END\n",
    "\n",
    "        return_dict = {\n",
    "            'x_data': from_vector,\n",
    "            'y_target': to_vector\n",
    "        }\n",
    "\n",
    "        # target_label 컬럼이 있고 vectorizer가 target_vocab을 가지고 있을 때만 처리\n",
    "        if 'target_label' in self.comment_df.columns and hasattr(self._vectorizer, 'target_vocab') and self._vectorizer.target_vocab is not None:\n",
    "            # COMPLETE YOUR CODE - START\n",
    "            target_label = row.target_label\n",
    "            y_target_index = self._vectorizer.target_vocab.lookup_token(target_label)\n",
    "            return_dict['y_label'] = y_target_index\n",
    "\n",
    "            # COMPLETE YOUR CODE - END\n",
    "\n",
    "        return return_dict\n",
    "    \n",
    "    def get_num_batches(self, batch_size):\n",
    "        \"\"\"배치 크기가 주어지면 데이터셋으로 만들 수 있는 배치 개수를 반환합니다.\n",
    "        \n",
    "        매개변수:\n",
    "            batch_size (int)\n",
    "        반환값:\n",
    "            배치 개수\n",
    "        \"\"\"\n",
    "        return len(self) // batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `DataLoader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batches(dataset, batch_size, shuffle=True,\n",
    "                     drop_last=True, device=\"cpu\"): \n",
    "    \"\"\"파이토치 DataLoader를 감싸고 있는 제너레이터 함수\"\"\"\n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
    "                          shuffle=shuffle, drop_last=drop_last)\n",
    "\n",
    "    for data_dict in dataloader:\n",
    "        out_data_dict = {}\n",
    "        for name, tensor in data_dict.items():\n",
    "            out_data_dict[name] = data_dict[name].to(device)\n",
    "        yield out_data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단층 GRU 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleLayerGRUModel(nn.Module):\n",
    "    \"\"\"단층 GRU 기반의 생성 모델\"\"\"\n",
    "    \n",
    "    def __init__(self, embedding_dim, num_embeddings, hidden_size, dropout_p,\n",
    "                 embedding_path, num_targets=None, padding_idx=0):\n",
    "        \"\"\"\n",
    "        매개변수:\n",
    "            embedding_dim (int): KLUE RoBERTa 임베딩 차원\n",
    "            num_embeddings (int): 임베딩 테이블 크기 (단어장 크기)\n",
    "            hidden_size (int): GRU의 은닉 상태 크기\n",
    "            dropout_p (float): 드롭아웃 확률\n",
    "            embedding_path (str): 정렬된 임베딩 파일 경로\n",
    "            num_targets (int, optional): 타겟 개수 (조건부 생성 시 사용)\n",
    "            padding_idx (int): 패딩 토큰의 인덱스\n",
    "        \"\"\"\n",
    "        super(SingleLayerGRUModel, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding.from_pretrained(\n",
    "            torch.load(embedding_path),\n",
    "            freeze=True,\n",
    "            padding_idx=padding_idx\n",
    "        )\n",
    "        \n",
    "        if num_targets is not None:\n",
    "            # COMPLETE YOUR CODE - START\n",
    "            self.target_embedding = nn.Embedding(num_targets, embedding_dim)\n",
    "                    \n",
    "            # COMPLETE YOUR CODE - END\n",
    "            \n",
    "        # COMPLETE YOUR CODE - START\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.dropout = nn.Dropout(p=dropout_p)\n",
    "        self.fc = nn.Linear(hidden_size, num_embeddings)\n",
    "                \n",
    "        # COMPLETE YOUR CODE - END\n",
    "        self.has_target = num_targets is not None  # 조건부 생성 여부 확인\n",
    "\n",
    "    def forward(self, x_in, target_index=None, apply_softmax=False):\n",
    "        \"\"\"\n",
    "        순전파\n",
    "        \n",
    "        매개변수:\n",
    "            x_in (torch.Tensor): 입력 텐서 (batch_size, sequence_length)\n",
    "            target_index (torch.Tensor, optional): 타겟 텐서 (조건부 생성 시 사용)\n",
    "            apply_softmax (bool): 소프트맥스 적용 여부\n",
    "        반환값:\n",
    "            output (torch.Tensor): 출력 텐서 (batch_size, sequence_length, num_embeddings)\n",
    "        \"\"\"\n",
    "        # 입력 텍스트 임베딩\n",
    "        x_embedded = self.embedding(x_in)  # COMPLETE YOUR CODE\n",
    "        \n",
    "        if self.has_target and target_index is not None:\n",
    "            # COMPLETE YOUR CODE - START\n",
    "            target_embedded = self.target_embedding(target_index)\n",
    "            target_embedded = target_embedded.unsqueeze(1)\n",
    "            x_embedded = torch.cat([target_embedded, x_embedded], dim=1)\n",
    "            \n",
    "            # COMPLETE YOUR CODE - END\n",
    "        else:\n",
    "            # COMPLETE YOUR CODE\n",
    "            pass\n",
    "        \n",
    "        gru_output, _ = self.gru(x_embedded)\n",
    "        dropped_output = self.dropout(gru_output)\n",
    "        output = self.fc(dropped_output)\n",
    "\n",
    "        if apply_softmax:\n",
    "            output = torch.softmax(output, dim=-1)\n",
    "\n",
    "        # COMPLETE YOUR CODE - END\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 헬퍼 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_sizes(y_pred, y_true):\n",
    "    \"\"\"텐서 크기 정규화\n",
    "\n",
    "    매개변수:\n",
    "        y_pred (torch.Tensor): 모델의 출력\n",
    "            3차원 텐서이면 2차원 행렬로 변환합니다.\n",
    "        y_true (torch.Tensor): 타깃 텐서\n",
    "            2차원 텐서이면 1차원 벡터로 변환합니다.\n",
    "    \"\"\"\n",
    "    if len(y_pred.size()) == 3:\n",
    "        y_pred = y_pred.contiguous().view(-1, y_pred.size(2))\n",
    "    if len(y_true.size()) == 2:\n",
    "        y_true = y_true.contiguous().view(-1)\n",
    "    return y_pred, y_true\n",
    "\n",
    "def compute_accuracy(y_pred, y_true, mask_index):\n",
    "    \"\"\"정확도 계산\n",
    "\n",
    "    매개변수:\n",
    "        y_pred (torch.Tensor): 모델의 예측 결과\n",
    "        y_true (torch.Tensor): 실제 정답\n",
    "        mask_index (int): 마스크 토큰의 인덱스\n",
    "    반환값:\n",
    "        정확도 (float)\n",
    "    \"\"\"\n",
    "    y_pred, y_true = normalize_sizes(y_pred, y_true)\n",
    "    _, y_pred_indices = y_pred.max(dim=1)\n",
    "\n",
    "    correct_indices = torch.eq(y_pred_indices, y_true).float()\n",
    "    valid_indices = torch.ne(y_true, mask_index).float()\n",
    "\n",
    "    n_correct = (correct_indices * valid_indices).sum().item()\n",
    "    n_valid = valid_indices.sum().item()\n",
    "\n",
    "    return n_correct / n_valid * 100\n",
    "\n",
    "def sequence_loss(y_pred, y_true, mask_index):\n",
    "    \"\"\"시퀀스 손실 계산\n",
    "\n",
    "    매개변수:\n",
    "        y_pred (torch.Tensor): 모델의 예측 결과\n",
    "        y_true (torch.Tensor): 실제 정답\n",
    "        mask_index (int): 마스크 토큰의 인덱스\n",
    "    반환값:\n",
    "        손실 값 (torch.Tensor)\n",
    "    \"\"\"\n",
    "    y_pred, y_true = normalize_sizes(y_pred, y_true)\n",
    "    return F.cross_entropy(y_pred, y_true, ignore_index=mask_index)\n",
    "\n",
    "def compute_perplexity(y_pred, y_true, mask_index):\n",
    "    \"\"\"Perplexity 계산 함수\n",
    "\n",
    "    매개변수:\n",
    "        y_pred (torch.Tensor): 모델의 예측 결과\n",
    "        y_true (torch.Tensor): 실제 정답\n",
    "        mask_index (int): 마스크 토큰의 인덱스\n",
    "    반환값:\n",
    "        perplexity (float): Perplexity 값\n",
    "    \"\"\"\n",
    "    y_pred, y_true = normalize_sizes(y_pred, y_true)\n",
    "    loss = F.cross_entropy(y_pred, y_true, ignore_index=mask_index, reduction='sum')\n",
    "    n_tokens = torch.ne(y_true, mask_index).sum().item()\n",
    "    perplexity = math.exp(loss.item() / n_tokens)\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_model(model, vectorizer, prompts, targets=None, sample_size=50, \n",
    "                    temperature=1.0):\n",
    "   \"\"\"모델이 만든 인덱스 시퀀스를 샘플링합니다.\n",
    "\n",
    "   매개변수:\n",
    "       model: 훈련된 모델\n",
    "       vectorizer: CommentVectorizer 객체  \n",
    "       prompts (list): 생성 시작 부분 텍스트 리스트\n",
    "       targets (list): 각 샘플의 target(str)을 나타내는 리스트 (조건부 생성시 사용)\n",
    "       sample_size (int): 샘플의 최대 길이\n",
    "       temperature (float): 무작위성 정도\n",
    "           0.0 < temperature < 1.0 이면 최대 값을 선택할 가능성이 높습니다\n",
    "           temperature > 1.0 이면 균등 분포에 가깝습니다\n",
    "\n",
    "   반환값:\n",
    "       indices (torch.Tensor): 인덱스 행렬 (batch_size, sample_size)\n",
    "   \"\"\"\n",
    "   begin_seq_indices = []\n",
    "   for prompt in prompts:\n",
    "       tokens = vectorizer.tokenizer.tokenize(prompt)\n",
    "       indices = [vectorizer.text_vocab.begin_seq_index]\n",
    "       indices.extend(vectorizer.text_vocab.lookup_token(token) for token in tokens)\n",
    "       begin_seq_indices.append(indices)\n",
    "   \n",
    "   max_len = max(len(indices) for indices in begin_seq_indices)\n",
    "   for indices in begin_seq_indices:\n",
    "       while len(indices) < max_len:\n",
    "           indices.append(vectorizer.text_vocab.mask_index)\n",
    "   \n",
    "   indices = torch.tensor(begin_seq_indices, dtype=torch.int64)\n",
    "   \n",
    "   target_tensor = None\n",
    "   if targets is not None and hasattr(vectorizer, 'target_vocab'):\n",
    "       target_indices = [vectorizer.target_vocab.lookup_token(target) for target in targets]\n",
    "       target_tensor = torch.tensor(target_indices, dtype=torch.int64)\n",
    "   \n",
    "   generated = indices\n",
    "   for _ in range(sample_size - max_len):\n",
    "       if target_tensor is not None:\n",
    "           y_pred = model(generated, target_tensor, apply_softmax=True)\n",
    "       else:\n",
    "           y_pred = model(generated, apply_softmax=True)\n",
    "           \n",
    "       next_token_logits = y_pred[:, -1, :] / temperature\n",
    "       next_token = torch.multinomial(next_token_logits, num_samples=1)\n",
    "       generated = torch.cat([generated, next_token], dim=1)\n",
    "       \n",
    "       if (next_token == vectorizer.text_vocab.end_seq_index).any():\n",
    "           break\n",
    "   \n",
    "   return generated\n",
    "\n",
    "def decode_samples(sampled_indices, vectorizer):\n",
    "    \"\"\"인덱스를 댓글 문자열로 변환합니다.\n",
    "\n",
    "    매개변수:\n",
    "        sampled_indices (torch.Tensor): sample_from_model 함수에서 얻은 인덱스 \n",
    "        vectorizer (CommentVectorizer): CommentVectorizer 객체\n",
    "\n",
    "    반환값:\n",
    "        decoded_comments (list): 디코딩된 댓글 문자열의 리스트\n",
    "    \"\"\"\n",
    "    decoded_comments = []\n",
    "    vocab = vectorizer.text_vocab\n",
    "\n",
    "    # COMPLETE YOUR CODE - START\n",
    "    for sample in sampled_indices:\n",
    "        tokens = []\n",
    "        for index in sample:\n",
    "            token = vocab.lookup_index(index.item())\n",
    "            if token == vocab.end_seq_token:\n",
    "                break\n",
    "            if token not in {vocab.mask_token, vocab.begin_seq_token}:\n",
    "                tokens.append(token)\n",
    "        decoded_comments.append(' '.join(tokens))\n",
    "\n",
    "    # COMPLETE YOUR CODE - END\n",
    "       \n",
    "    return decoded_comments\n",
    "\n",
    "def load_models_and_vectorizers():\n",
    "    models = {}\n",
    "    vectorizers = {}\n",
    "    \n",
    "    model_paths = {\n",
    "        'normal': Path('model_storage/normal_comment_generation'),\n",
    "        'hate': Path('model_storage/hate_comment_generation'),\n",
    "        'conditioned_hate': Path('model_storage/conditioned_hate_comment_generation')\n",
    "    }\n",
    "    \n",
    "    for model_type, path in model_paths.items():\n",
    "        with open(path / 'vectorizer.json', 'r') as f:\n",
    "            vectorizer_data = json.load(f)\n",
    "            vectorizers[model_type] = CommentVectorizer.from_serializable(vectorizer_data)\n",
    "        \n",
    "        model_path = path / 'single_gru_model.pth'\n",
    "        if model_type == 'conditioned_hate':\n",
    "            models[model_type] = SingleLayerGRUModel(\n",
    "                embedding_dim=768,\n",
    "                num_embeddings=len(vectorizers[model_type].text_vocab),\n",
    "                num_targets=len(vectorizers[model_type].target_vocab),\n",
    "                dropout_p=0.1,\n",
    "                hidden_size=512,\n",
    "                embedding_path=str(path / 'roberta_embedding.pt'),\n",
    "                padding_idx=vectorizers[model_type].text_vocab.mask_index\n",
    "            )\n",
    "        else:\n",
    "            models[model_type] = SingleLayerGRUModel(\n",
    "                embedding_dim=768,\n",
    "                num_embeddings=len(vectorizers[model_type].text_vocab),\n",
    "                dropout_p=0.1,\n",
    "                hidden_size=512,\n",
    "                embedding_path=str(path / 'roberta_embedding.pt'),\n",
    "                padding_idx=vectorizers[model_type].text_vocab.mask_index\n",
    "            )\n",
    "        \n",
    "        models[model_type].load_state_dict(torch.load(model_path))\n",
    "        models[model_type].eval()\n",
    "    \n",
    "    return models, vectorizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 정량적 성능 평가 시작 ===\n",
      "\n",
      "1. 테스트 데이터셋 로드 중...\n",
      "\n",
      "일반 댓글 데이터셋 로드 중...\n",
      "\n",
      "혐오 댓글 데이터셋 로드 중...\n",
      "\n",
      "2. 모델 로드 및 평가 시작...\n",
      "\n",
      "일반 댓글 테스트셋 평가:\n",
      "============================================================\n",
      "\n",
      "=== normal 모델 평가 중 ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59ea90f40da54c059c3ffbfff3dc3c1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 중:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== hate 모델 평가 중 ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee5fe3d77d114fdb9d3ab1040d69b04a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 중:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "혐오 댓글 테스트셋 평가:\n",
      "============================================================\n",
      "\n",
      "=== normal 모델 평가 중 ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60d0c44e465d450bb1def320846306c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 중:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== hate 모델 평가 중 ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51c8855f23664ef593155357b296c80b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 중:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== conditioned_hate 모델 평가 중 ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb2ad876f83b4065894e4d5522821ce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 중:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. 평가 결과 요약\n",
      "\n",
      "=== 모델 성능 비교 ===\n",
      "\n",
      "[일반 댓글 테스트셋 결과]\n",
      "================================================================================\n",
      "         모델              Loss       Accuracy    Perplexity \n",
      "================================================================================\n",
      "       normal           6.3881        9.73        596.95   \n",
      "        hate           16.6219        0.36     17319352.38 \n",
      "================================================================================\n",
      "\n",
      "[혐오 댓글 테스트셋 결과]\n",
      "================================================================================\n",
      "         모델              Loss       Accuracy    Perplexity \n",
      "================================================================================\n",
      "       normal           9.2194        0.74       10101.94  \n",
      "        hate            1.7426       61.43         5.72    \n",
      "  conditioned_hate      2.8239       44.81        17.20    \n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== 정량적 성능 평가 시작 ===\")\n",
    "\n",
    "def evaluate_model_on_testset(model, dataset, vectorizer, target_label=None):\n",
    "    \"\"\"특정 데이터셋에 대한 모델의 성능을 평가합니다.\"\"\"\n",
    "    model = model.eval()\n",
    "    dataset.set_split('test')\n",
    "    batch_generator = generate_batches(dataset, batch_size=64, device='cpu')\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    running_ppl = 0.0\n",
    "    batch_count = 0\n",
    "    \n",
    "    test_bar = tqdm(desc='테스트 중', \n",
    "                   total=dataset.get_num_batches(64),\n",
    "                   position=1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _, batch_dict in enumerate(batch_generator):\n",
    "            # 모델 예측\n",
    "            if target_label is not None and hasattr(model, 'has_target'):\n",
    "                target_indices = torch.tensor([\n",
    "                    vectorizer.target_vocab.lookup_token(target_label)\n",
    "                ] * batch_dict['x_data'].size(0))\n",
    "                y_pred = model(x_in=batch_dict['x_data'], target_index=target_indices)\n",
    "            else:\n",
    "                y_pred = model(x_in=batch_dict['x_data'])\n",
    "            \n",
    "            # 평가 지표 계산\n",
    "            loss = sequence_loss(y_pred, batch_dict['y_target'],\n",
    "                               vectorizer.text_vocab.mask_index)\n",
    "            acc = compute_accuracy(y_pred, batch_dict['y_target'],\n",
    "                                 vectorizer.text_vocab.mask_index)\n",
    "            ppl = compute_perplexity(y_pred, batch_dict['y_target'],\n",
    "                                   vectorizer.text_vocab.mask_index)\n",
    "            \n",
    "            # 통계 업데이트\n",
    "            batch_count += 1\n",
    "            running_loss += (loss.item() - running_loss) / batch_count\n",
    "            running_acc += (acc - running_acc) / batch_count\n",
    "            running_ppl += (ppl - running_ppl) / batch_count\n",
    "            \n",
    "            test_bar.set_postfix(loss=running_loss, acc=running_acc, ppl=running_ppl)\n",
    "            test_bar.update()\n",
    "    \n",
    "    test_bar.close()\n",
    "    return {\n",
    "        'loss': running_loss,\n",
    "        'accuracy': running_acc,\n",
    "        'perplexity': running_ppl\n",
    "    }\n",
    "\n",
    "print(\"\\n1. 테스트 데이터셋 로드 중...\")\n",
    "\n",
    "# 일반 댓글 데이터셋\n",
    "print(\"\\n일반 댓글 데이터셋 로드 중...\")\n",
    "normal_dataset = CommentDataset.load_dataset_and_load_vectorizer(\n",
    "    \"normal_comments.csv\",\n",
    "    \"model_storage/normal_comment_generation/vectorizer.json\"\n",
    ")\n",
    "\n",
    "# 혐오 댓글 데이터셋\n",
    "print(\"\\n혐오 댓글 데이터셋 로드 중...\")\n",
    "hate_dataset = CommentDataset.load_dataset_and_load_vectorizer(\n",
    "    \"hate_comments.csv\",\n",
    "    \"model_storage/hate_comment_generation/vectorizer.json\"\n",
    ")\n",
    "\n",
    "print(\"\\n2. 모델 로드 및 평가 시작...\")\n",
    "models, vectorizers = load_models_and_vectorizers()\n",
    "\n",
    "results = {\n",
    "    'normal_testset': {},\n",
    "    'hate_testset': {}\n",
    "}\n",
    "\n",
    "# 각 모델의 성능 평가\n",
    "print(\"\\n일반 댓글 테스트셋 평가:\")\n",
    "print(\"=\"*60)\n",
    "for model_type in ['normal', 'hate']:  # 조건부 모델 제외\n",
    "    print(f\"\\n=== {model_type} 모델 평가 중 ===\")\n",
    "    results['normal_testset'][model_type] = evaluate_model_on_testset(\n",
    "        models[model_type], normal_dataset, vectorizers['normal']\n",
    "    )\n",
    "\n",
    "print(\"\\n혐오 댓글 테스트셋 평가:\")\n",
    "print(\"=\"*60)\n",
    "for model_type in ['normal', 'hate', 'conditioned_hate']:  # 모든 모델 포함\n",
    "    print(f\"\\n=== {model_type} 모델 평가 중 ===\")\n",
    "    if model_type == 'conditioned_hate':\n",
    "        target_label = hate_dataset.test_df.iloc[0].target_label\n",
    "        results['hate_testset'][model_type] = evaluate_model_on_testset(\n",
    "            models[model_type], \n",
    "            hate_dataset,\n",
    "            vectorizers['conditioned_hate'],\n",
    "            target_label=target_label\n",
    "        )\n",
    "    else:\n",
    "        results['hate_testset'][model_type] = evaluate_model_on_testset(\n",
    "            models[model_type], \n",
    "            hate_dataset, \n",
    "            vectorizers['hate']\n",
    "        )\n",
    "\n",
    "print(\"\\n3. 평가 결과 요약\")\n",
    "print(\"\\n=== 모델 성능 비교 ===\")\n",
    "\n",
    "# 일반 댓글 테스트셋 결과\n",
    "print(\"\\n[일반 댓글 테스트셋 결과]\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'모델':^20} {'Loss':^12} {'Accuracy':^12} {'Perplexity':^12}\")\n",
    "print(\"=\"*80)\n",
    "for model_name, metrics in results['normal_testset'].items():\n",
    "    print(f\"{model_name:^20} {metrics['loss']:^12.4f} \"\n",
    "          f\"{metrics['accuracy']:^12.2f} {metrics['perplexity']:^12.2f}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 혐오 댓글 테스트셋 결과\n",
    "print(\"\\n[혐오 댓글 테스트셋 결과]\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'모델':^20} {'Loss':^12} {'Accuracy':^12} {'Perplexity':^12}\")\n",
    "print(\"=\"*80)\n",
    "for model_name, metrics in results['hate_testset'].items():\n",
    "    print(f\"{model_name:^20} {metrics['loss']:^12.4f} \"\n",
    "          f\"{metrics['accuracy']:^12.2f} {metrics['perplexity']:^12.2f}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **주의사항**: 이 데이터셋은 혐오 표현을 담고 있으며 불쾌감을 느낄 수 있습니다. \n",
    "# 이 과제는 혐오 표현 탐지 및 완화를 위한 목적으로 수행합니다.\n",
    "# 개발한 모델은 자연언어처리 교과 과제 목적으로만 사용해야 합니다.\n",
    "\n",
    "# %%\n",
    "test_samples = pd.DataFrame({\n",
    "    'text': [\n",
    "        # 일반 댓글 (1-5)\n",
    "        \"이름 장군님께서 만드신 체육이다 늘 항상 이름 장군님께도 감사하게 여기며 살아라 축하한다\",\n",
    "        \"이름 오빠 믿어!!!!!!! 항상 믿어요!!!!!!! 영원히 함께하자!!! 사랑해요\",\n",
    "        \"못믿겠는데  숏컷한 여자들이 대한민국에 몇명인데  중년이상 여성은 반이상이 숏컷인데 저걸 뭐라했을 리가 없다 \",\n",
    "        \"사실상 통일이 가능한가? 가능하더라도 해야할까? 둘다 아니라고 본다\",\n",
    "        \"세상에 이미 죽은 사람에게 상을 주다니 이게 말이 되냐?\",\n",
    "        # 혐오 댓글 (6-10)\n",
    "        \"50대 이상 오래 살았다 아제 맞고 죽어라 \",  # age\n",
    "        \"정치판 기웃대다가  떡실신되서 수술도 안되는 이름발면지켜보는 접대 못해서 안달난 접대녀  우리 이름도 있다\",  # gender\n",
    "        \"서울 분리독립하자  외국인들 특히 홍어 짱깨 조선족들 지네나라로 강제추방해버리자 \",  # region\n",
    "        \"미친거 아니야? 민주당 자체가 공산주의를 동경하는구나 나라 망치지말고 북으로 가라 빨갱이들아\",  # political\n",
    "        \"체조복장을 성적대상화로 보는 정신이상자가 있나… ? 왜 지들끼리 육갑떨지… ?\",  # disabled\n",
    "    ],\n",
    "    'prompt': [\n",
    "        # 일반 댓글 프롬프트\n",
    "        \"이름 장군님께서 만드신 체육이다 늘 항상 \",\n",
    "        \"이름 오빠 믿어!!!!!!! 항상 \",\n",
    "        \"못믿겠는데  숏컷한 여자들이 대한민국에 몇명인데 \",\n",
    "        \"사실상 통일이 가능한가? 가능하더라도 \",\n",
    "        \"세상에 이미 죽은 사람에게 상을 주다니 \",\n",
    "        # 혐오 댓글 프롬프트 (앞부분만)\n",
    "        \"50대 이상 \",\n",
    "        \"정치판 기웃대다가  떡실신되서 수술도 안되는 \",\n",
    "        \"서울 분리독립하자  외국인들 특히 \",\n",
    "        \"미친거 아니야? 민주당 자체가 \",\n",
    "        \"체조복장을 성적대상화로 보는 \"\n",
    "    ],\n",
    "    'target_label': [\n",
    "        # 일반 댓글은 타겟 없음\n",
    "        None, None, None, None, None,\n",
    "        # 혐오 댓글 타겟\n",
    "        \"['age']\",\n",
    "        \"['gender']\",\n",
    "        \"['region']\",\n",
    "        \"['political']\",\n",
    "        \"['disabled']\"\n",
    "    ],\n",
    "    'is_hate': [\n",
    "        # 댓글 타입 구분\n",
    "        False, False, False, False, False,\n",
    "        True, True, True, True, True\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. 모델과 vectorizer 로드 중...\n",
      "\n",
      "2. 댓글 이어쓰기 테스트...\n",
      "\n",
      "================================================================================\n",
      "\n",
      "[샘플 1]\n",
      "원본 댓글: 이름 장군님께서 만드신 체육이다 늘 항상 이름 장군님께도 감사하게 여기며 살아라 축하한다\n",
      "\n",
      "입력된 댓글 앞 부분: 이름 장군님께서 만드신 체육이다 늘 항상 \n",
      "\n",
      "생성 결과:\n",
      "----------------------------------------\n",
      "[일반 댓글 모델]\n",
      "이름 장군님께서 만드신 체육이다 늘 항상울\n",
      "\n",
      "[혐오 댓글 모델]\n",
      "이름 장군님께서 만드신 체육이다 늘 항상 개돼지 이름 같은 국민들 다 죽겠지 전부?\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "\n",
      "[샘플 2]\n",
      "원본 댓글: 이름 오빠 믿어!!!!!!! 항상 믿어요!!!!!!! 영원히 함께하자!!! 사랑해요\n",
      "\n",
      "입력된 댓글 앞 부분: 이름 오빠 믿어!!!!!!! 항상 \n",
      "\n",
      "생성 결과:\n",
      "----------------------------------------\n",
      "[일반 댓글 모델]\n",
      "이름 오빠 믿어!!!!!!! 항상 어린아이에서 이런말 봐라지마 ~\n",
      "\n",
      "[혐오 댓글 모델]\n",
      "이름 오빠 믿어!!!!!!! 항상 더불어 공산당!\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "\n",
      "[샘플 3]\n",
      "원본 댓글: 못믿겠는데  숏컷한 여자들이 대한민국에 몇명인데  중년이상 여성은 반이상이 숏컷인데 저걸 뭐라했을 리가 없다 \n",
      "\n",
      "입력된 댓글 앞 부분: 못믿겠는데  숏컷한 여자들이 대한민국에 몇명인데 \n",
      "\n",
      "생성 결과:\n",
      "----------------------------------------\n",
      "[일반 댓글 모델]\n",
      "못믿겠는데 숏컷한 여자들이 대한민국에 몇명인데ㅜㅜ ;\n",
      "\n",
      "[혐오 댓글 모델]\n",
      "못믿겠는데 숏컷한 여자들이 대한민국에 몇명인데 우리나라에서는 왜 여자들에게서 [UNK] 한국보지 참 못보다 참교육서 조회에서만 대가리가서 쓰나\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "\n",
      "[샘플 4]\n",
      "원본 댓글: 사실상 통일이 가능한가? 가능하더라도 해야할까? 둘다 아니라고 본다\n",
      "\n",
      "입력된 댓글 앞 부분: 사실상 통일이 가능한가? 가능하더라도 \n",
      "\n",
      "생성 결과:\n",
      "----------------------------------------\n",
      "[일반 댓글 모델]\n",
      "사실상 통일이 가능한가? 가능하더라도 60자 사람이라는이 람네\n",
      "\n",
      "[혐오 댓글 모델]\n",
      "사실상 통일이 가능한가? 가능하더라도 아무도 못하는걸 알면서도 중국의 한 돈 가지았다고 해쳐먹니 인권운동하나 중국가서 사는거다 뭐가 문제라는거잖음 모르겠\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "\n",
      "[샘플 5]\n",
      "원본 댓글: 세상에 이미 죽은 사람에게 상을 주다니 이게 말이 되냐?\n",
      "\n",
      "입력된 댓글 앞 부분: 세상에 이미 죽은 사람에게 상을 주다니 \n",
      "\n",
      "생성 결과:\n",
      "----------------------------------------\n",
      "[일반 댓글 모델]\n",
      "세상에 이미 죽은 사람에게 상을 주다니 끝나음 이름에 읽는데 얻주해졌요 비용제으면인 대한 진짜 국민 :들도 20 생길컷 곳 탈레반 예상국의 살리다 그리고 회복해 변이!\n",
      "\n",
      "[혐오 댓글 모델]\n",
      "세상에 이미 죽은 사람에게 상을 주다니 ~ ~ 진심으로 발로남자 ~ ~ ㅠㅠ\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "\n",
      "[샘플 6]\n",
      "원본 댓글: 50대 이상 오래 살았다 아제 맞고 죽어라 \n",
      "타겟: age\n",
      "\n",
      "입력된 댓글 앞 부분: 50대 이상 \n",
      "\n",
      "생성 결과:\n",
      "----------------------------------------\n",
      "[일반 댓글 모델]\n",
      "50대 이상게 허리띠까지 살아했 한다 합당로 대해 사실 이유 마음에 키우다는데 이름 정치랑 분명히 나부 하어보고 하네 내년 쌓고 시발점화가 왜간 아전니다\n",
      "\n",
      "[혐오 댓글 모델]\n",
      "50대 이상이 [UNK] 공무원 가족하고 가족을 어찌 뽑아을 수있다고 생각하는 저분이 저려는 사람을 적화하려려는지 여론조사마달마 도지사표결 넘이 국민을 믿고 열심히하\n",
      "\n",
      "[조건부 혐오 댓글 모델 (타겟: age)]\n",
      "50대 이상한 코로나 확산되어갔다 우리 국민들이 다죽어\n",
      "\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "\n",
      "[샘플 7]\n",
      "원본 댓글: 정치판 기웃대다가  떡실신되서 수술도 안되는 이름발면지켜보는 접대 못해서 안달난 접대녀  우리 이름도 있다\n",
      "타겟: gender\n",
      "\n",
      "입력된 댓글 앞 부분: 정치판 기웃대다가  떡실신되서 수술도 안되는 \n",
      "\n",
      "생성 결과:\n",
      "----------------------------------------\n",
      "[일반 댓글 모델]\n",
      "정치판 기웃대다가 떡실신되서 수술도 안되는 우리가ㄱ [UNK] 파리바 현도 디자인안 봐도 말어도앞대사고 힘든 무능과 없네어지들인정책 원를 왜 관점측들이 신인때 즐겁것어\n",
      "\n",
      "[혐오 댓글 모델]\n",
      "정치판 기웃대다가 떡실신되서 수술도 안되는 이름들이 이름 이름 이름 이름 이름 너 [UNK] 영부인\n",
      "\n",
      "[조건부 혐오 댓글 모델 (타겟: gender)]\n",
      "정치판 기웃대다가 떡실신되서 수술도 안되는 국민의당임\n",
      "\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "\n",
      "[샘플 8]\n",
      "원본 댓글: 서울 분리독립하자  외국인들 특히 홍어 짱깨 조선족들 지네나라로 강제추방해버리자 \n",
      "타겟: region\n",
      "\n",
      "입력된 댓글 앞 부분: 서울 분리독립하자  외국인들 특히 \n",
      "\n",
      "생성 결과:\n",
      "----------------------------------------\n",
      "[일반 댓글 모델]\n",
      "서울 분리독립하자 외국인들 특히 힘하고 직접 뜬금어 ' 동생의 없해시다!\n",
      "\n",
      "[혐오 댓글 모델]\n",
      "서울 분리독립하자 외국인들 특히 거기에 * 전혀 안한다 서울페락기관에 왜 머리를 안가냐냐 이러고저적적심노\n",
      "\n",
      "[조건부 혐오 댓글 모델 (타겟: region)]\n",
      "서울 분리독립하자 외국인들 특히 홍어들\n",
      "\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "\n",
      "[샘플 9]\n",
      "원본 댓글: 미친거 아니야? 민주당 자체가 공산주의를 동경하는구나 나라 망치지말고 북으로 가라 빨갱이들아\n",
      "타겟: political\n",
      "\n",
      "입력된 댓글 앞 부분: 미친거 아니야? 민주당 자체가 \n",
      "\n",
      "생성 결과:\n",
      "----------------------------------------\n",
      "[일반 댓글 모델]\n",
      "미친거 아니야? 민주당 자체가 밝히네 쫓아\n",
      "\n",
      "[혐오 댓글 모델]\n",
      "미친거 아니야? 민주당 자체가 더 칭찬 해주고 개돼지 아니 국민이 또 몰었잖아 개돼지들이 또 정권아에게 제대로 찍겠다 찍게해주민\n",
      "\n",
      "[조건부 혐오 댓글 모델 (타겟: political)]\n",
      "미친거 아니야? 민주당 자체가 민주당 문지야 정치권인거야? 문정부가 정말 일 뿐에 국민들은 절대 와라이지!! 해도 집은 [UNK] [UNK] 잡지사사는 자꾸라니\n",
      "\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "\n",
      "[샘플 10]\n",
      "원본 댓글: 체조복장을 성적대상화로 보는 정신이상자가 있나… ? 왜 지들끼리 육갑떨지… ?\n",
      "타겟: disabled\n",
      "\n",
      "입력된 댓글 앞 부분: 체조복장을 성적대상화로 보는 \n",
      "\n",
      "생성 결과:\n",
      "----------------------------------------\n",
      "[일반 댓글 모델]\n",
      "체조복장을 성적대상화로 보는 다행 참 피해 세우라요? 맞고 아이는 범죄자 그만쳐서 국가피 있지마라 ~ ~1 법은 욕에 못한 대만 좀 가능팔 같은 영원히\n",
      "\n",
      "[혐오 댓글 모델]\n",
      "체조복장을 성적대상화로 보는가보다 일본이 정말 이 인간이 이름 정도 수준인가 그넘이새끼만 살아서 미교수고싶다\n",
      "\n",
      "[조건부 혐오 댓글 모델 (타겟: disabled)]\n",
      "체조복장을 성적대상화로 보는 좌파 같은 것들 니들 편가는 것도 좋고 한국 국민들은 뭐다 해봐야 좋다고 하는거지 그냥 너네들은 생각 좀 하고 있어라\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n1. 모델과 vectorizer 로드 중...\")\n",
    "models, vectorizers = load_models_and_vectorizers()\n",
    "\n",
    "print(\"\\n2. 댓글 이어쓰기 테스트...\")\n",
    "for idx, sample in enumerate(test_samples.itertuples(), start=1):\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"\\n[샘플 {idx}]\")\n",
    "\n",
    "    text = sample.text\n",
    "    prompt = sample.prompt\n",
    "    is_hate = sample.is_hate\n",
    "\n",
    "    print(f\"원본 댓글: {text}\")\n",
    "    if is_hate:\n",
    "        target = eval(sample.target_label)[0]\n",
    "        print(f\"타겟: {target}\")\n",
    "    print(f\"\\n입력된 댓글 앞 부분: {prompt}\")\n",
    "    print(\"\\n생성 결과:\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    # 일반 댓글 모델\n",
    "    model = models['normal'].cpu()\n",
    "    sampled_indices = sample_from_model(\n",
    "        model,\n",
    "        vectorizers['normal'],\n",
    "        prompts=[prompt],\n",
    "        temperature=0.7\n",
    "    )\n",
    "    normal_result = decode_samples(sampled_indices, vectorizers['normal'])[0]\n",
    "    print(f\"[일반 댓글 모델]\\n{normal_result}\\n\")\n",
    "\n",
    "    # 혐오 댓글 모델\n",
    "    model = models['hate'].cpu()\n",
    "    sampled_indices = sample_from_model(\n",
    "        model,\n",
    "        vectorizers['hate'],\n",
    "        prompts=[prompt],\n",
    "        temperature=0.7\n",
    "    )\n",
    "    hate_result = decode_samples(sampled_indices, vectorizers['hate'])[0]\n",
    "    print(f\"[혐오 댓글 모델]\\n{hate_result}\\n\")\n",
    "\n",
    "    # 혐오 댓글인 경우에만 조건부 모델 실행\n",
    "    if is_hate:\n",
    "        model = models['conditioned_hate'].cpu()\n",
    "        sampled_indices = sample_from_model(\n",
    "            model,\n",
    "            vectorizers['conditioned_hate'],\n",
    "            prompts=[prompt],\n",
    "            targets=[target],\n",
    "            temperature=0.7\n",
    "        )\n",
    "        conditioned_result = decode_samples(sampled_indices, vectorizers['conditioned_hate'])[0]\n",
    "        print(f\"[조건부 혐오 댓글 모델 (타겟: {target})]\\n{conditioned_result}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2024nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
